{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9132bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from torch.nn.functional import interpolate\n",
    "from kmeans_pytorch import kmeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "def sam2_generate_mask(image_path, model_cfg, checkpoint, device=\"cuda\"):\n",
    "    \"\"\"用SAM2生成整数mask (H, W)，每个区域对应一个ID\"\"\"\n",
    "    # 读取图像\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # 构建SAM2\n",
    "    sam2 = build_sam2(model_cfg, checkpoint, device=torch.device(device), apply_postprocessing=False)\n",
    "    mask_generator = SAM2AutomaticMaskGenerator(model=sam2, use_m2m=False)\n",
    "\n",
    "    # 生成mask\n",
    "    anns = mask_generator.generate(image_np)\n",
    "\n",
    "    # 转换为单通道整数mask\n",
    "    h, w, _ = image_np.shape\n",
    "    masks = np.zeros((h, w), dtype=np.int32)\n",
    "    for idx, ann in enumerate(anns, start=1):\n",
    "        m = ann[\"segmentation\"]\n",
    "        masks[m] = idx  # 每个mask区域赋一个唯一的ID\n",
    "\n",
    "    return image_np, masks\n",
    "\n",
    "def filter_points_by_bounds(points, bounds_min, bounds_max, strict=True):\n",
    "    \"\"\"过滤掉超出工作空间范围的点\"\"\"\n",
    "    assert points.shape[1] == 3, \"points must be (N, 3)\"\n",
    "    bounds_min = bounds_min.copy()\n",
    "    bounds_max = bounds_max.copy()\n",
    "    if not strict:\n",
    "        bounds_min[:2] -= 0.1 * (bounds_max[:2] - bounds_min[:2])\n",
    "        bounds_max[:2] += 0.1 * (bounds_max[:2] - bounds_min[:2])\n",
    "        bounds_min[2] -= 0.1 * (bounds_max[2] - bounds_min[2])\n",
    "    mask = (\n",
    "        (points[:, 0] >= bounds_min[0]) & (points[:, 0] <= bounds_max[0]) &\n",
    "        (points[:, 1] >= bounds_min[1]) & (points[:, 1] <= bounds_max[1]) &\n",
    "        (points[:, 2] >= bounds_min[2]) & (points[:, 2] <= bounds_max[2])\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def preprocess(rgb, points, masks, patch_size=14):\n",
    "    \"\"\"预处理输入数据，调整RGB大小，生成二值mask\"\"\"\n",
    "    masks = [masks == uid for uid in np.unique(masks)]\n",
    "\n",
    "    H, W, _ = rgb.shape\n",
    "    patch_h = H // patch_size\n",
    "    patch_w = W // patch_size\n",
    "    new_H, new_W = patch_h * patch_size, patch_w * patch_size\n",
    "\n",
    "    transformed_rgb = cv2.resize(rgb, (new_W, new_H)).astype(np.float32) / 255.0\n",
    "\n",
    "    shape_info = {\n",
    "        'img_h': H,\n",
    "        'img_w': W,\n",
    "        'patch_h': patch_h,\n",
    "        'patch_w': patch_w,\n",
    "    }\n",
    "    return transformed_rgb, rgb, points, masks, shape_info\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "@torch.amp.autocast('cuda')\n",
    "def get_features(dinov2, transformed_rgb, shape_info, device):\n",
    "    \"\"\"用DINOv2提取特征\"\"\"\n",
    "    img_h, img_w = shape_info['img_h'], shape_info['img_w']\n",
    "    patch_h, patch_w = shape_info['patch_h'], shape_info['patch_w']\n",
    "\n",
    "    img_tensors = torch.from_numpy(transformed_rgb).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "    features_dict = dinov2.forward_features(img_tensors)\n",
    "    raw_feature_grid = features_dict['x_norm_patchtokens']  # [1, patch_h*patch_w, C]\n",
    "    raw_feature_grid = raw_feature_grid.reshape(1, patch_h, patch_w, -1)\n",
    "\n",
    "    interpolated = interpolate(\n",
    "        raw_feature_grid.permute(0, 3, 1, 2),\n",
    "        size=(img_h, img_w),\n",
    "        mode='bilinear'\n",
    "    ).permute(0, 2, 3, 1).squeeze(0)\n",
    "\n",
    "    features_flat = interpolated.reshape(-1, interpolated.shape[-1])\n",
    "    return features_flat\n",
    "\n",
    "\n",
    "def cluster_features(points, features_flat, masks, config, device):\n",
    "    \"\"\"对mask区域特征聚类，获取候选点\"\"\"\n",
    "    candidate_keypoints, candidate_pixels, candidate_rigid_group_ids = [], [], []\n",
    "\n",
    "    for rigid_group_id, binary_mask in enumerate(masks):\n",
    "        if np.mean(binary_mask) > config['max_mask_ratio']:\n",
    "            continue\n",
    "\n",
    "        obj_features = features_flat[binary_mask.reshape(-1)]\n",
    "        feature_pixels = np.argwhere(binary_mask)\n",
    "        feature_points = points[binary_mask]\n",
    "\n",
    "        obj_features = obj_features.double()\n",
    "        u, s, v = torch.pca_lowrank(obj_features, center=False)\n",
    "        features_pca = torch.mm(obj_features, v[:, :3])\n",
    "\n",
    "        features_pca = (features_pca - features_pca.min(0)[0]) / (\n",
    "            features_pca.max(0)[0] - features_pca.min(0)[0]\n",
    "        )\n",
    "\n",
    "        feature_points_torch = torch.tensor(\n",
    "            feature_points, dtype=features_pca.dtype, device=features_pca.device\n",
    "        )\n",
    "        feature_points_torch = (feature_points_torch - feature_points_torch.min(0)[0]) / (\n",
    "            feature_points_torch.max(0)[0] - feature_points_torch.min(0)[0]\n",
    "        )\n",
    "        X = torch.cat([features_pca, feature_points_torch], dim=-1)\n",
    "\n",
    "        cluster_ids, cluster_centers = kmeans(\n",
    "            X=X,\n",
    "            num_clusters=config['num_candidates_per_mask'],\n",
    "            distance='euclidean',\n",
    "            device=device,\n",
    "        )\n",
    "        cluster_centers = cluster_centers.to(device)\n",
    "\n",
    "        for cluster_id in range(config['num_candidates_per_mask']):\n",
    "            cluster_center = cluster_centers[cluster_id][:3]\n",
    "            member_idx = cluster_ids == cluster_id\n",
    "            member_points = feature_points[member_idx]\n",
    "            member_pixels = feature_pixels[member_idx]\n",
    "            member_features = features_pca[member_idx]\n",
    "\n",
    "            dist = torch.norm(member_features - cluster_center, dim=-1)\n",
    "            closest_idx = torch.argmin(dist)\n",
    "\n",
    "            candidate_keypoints.append(member_points[closest_idx])\n",
    "            candidate_pixels.append(member_pixels[closest_idx])\n",
    "            candidate_rigid_group_ids.append(rigid_group_id)\n",
    "\n",
    "    return (\n",
    "        np.array(candidate_keypoints),\n",
    "        np.array(candidate_pixels),\n",
    "        np.array(candidate_rigid_group_ids)\n",
    "    )\n",
    "\n",
    "\n",
    "def merge_clusters(candidate_keypoints, min_dist_bt_keypoints):\n",
    "    \"\"\"用MeanShift合并相近的候选点\"\"\"\n",
    "    ms = MeanShift(bandwidth=min_dist_bt_keypoints, bin_seeding=True, n_jobs=32)\n",
    "    ms.fit(candidate_keypoints)\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    merged_indices = []\n",
    "    for center in cluster_centers:\n",
    "        dist = np.linalg.norm(candidate_keypoints - center, axis=-1)\n",
    "        merged_indices.append(np.argmin(dist))\n",
    "    return merged_indices\n",
    "\n",
    "\n",
    "def project_keypoints_to_img(rgb, candidate_pixels):\n",
    "    \"\"\"在图像上画关键点\"\"\"\n",
    "    projected = rgb.copy()\n",
    "    for idx, pixel in enumerate(candidate_pixels):\n",
    "        text = str(idx)\n",
    "        box_w, box_h = 30, 30\n",
    "        cv2.rectangle(\n",
    "            projected,\n",
    "            (pixel[1] - box_w // 2, pixel[0] - box_h // 2),\n",
    "            (pixel[1] + box_w // 2, pixel[0] + box_h // 2),\n",
    "            (255, 255, 255), -1\n",
    "        )\n",
    "        cv2.rectangle(\n",
    "            projected,\n",
    "            (pixel[1] - box_w // 2, pixel[0] - box_h // 2),\n",
    "            (pixel[1] + box_w // 2, pixel[0] + box_h // 2),\n",
    "            (0, 0, 0), 2\n",
    "        )\n",
    "        org = (pixel[1] - 7 * len(text), pixel[0] + 7)\n",
    "        cv2.putText(projected, text, org, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    return projected\n",
    "\n",
    "\n",
    "def get_keypoints(rgb, points, masks, dinov2, config):\n",
    "    \"\"\"整体关键点提取流程\"\"\"\n",
    "    device = torch.device(config['device'])\n",
    "\n",
    "    transformed_rgb, rgb, points, masks, shape_info = preprocess(\n",
    "        rgb, points, masks, patch_size=14\n",
    "    )\n",
    "\n",
    "    features_flat = get_features(dinov2, transformed_rgb, shape_info, device)\n",
    "\n",
    "    candidate_keypoints, candidate_pixels, candidate_rigid_group_ids = cluster_features(\n",
    "        points, features_flat, masks, config, device\n",
    "    )\n",
    "\n",
    "    within_space = filter_points_by_bounds(\n",
    "        candidate_keypoints, np.array(config['bounds_min']), np.array(config['bounds_max']), strict=True\n",
    "    )\n",
    "    candidate_keypoints = candidate_keypoints[within_space]\n",
    "    candidate_pixels = candidate_pixels[within_space]\n",
    "    candidate_rigid_group_ids = candidate_rigid_group_ids[within_space]\n",
    "\n",
    "    merged_indices = merge_clusters(candidate_keypoints, config['min_dist_bt_keypoints'])\n",
    "    candidate_keypoints = candidate_keypoints[merged_indices]\n",
    "    candidate_pixels = candidate_pixels[merged_indices]\n",
    "    candidate_rigid_group_ids = candidate_rigid_group_ids[merged_indices]\n",
    "\n",
    "    sort_idx = np.lexsort((candidate_pixels[:, 0], candidate_pixels[:, 1]))\n",
    "    candidate_keypoints = candidate_keypoints[sort_idx]\n",
    "    candidate_pixels = candidate_pixels[sort_idx]\n",
    "    candidate_rigid_group_ids = candidate_rigid_group_ids[sort_idx]\n",
    "\n",
    "    projected = project_keypoints_to_img(rgb, candidate_pixels)\n",
    "    return candidate_keypoints, projected\n",
    "\n",
    "# 1. 加载模型\n",
    "dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').eval().to('cuda')\n",
    "sam2_checkpoint = \"./models/sam2/sam2_hiera_base_plus.pt\"\n",
    "model_cfg_0 = \"configs/sam2/sam2_hiera_b+.yaml\"\n",
    "\n",
    "rgb, masks = sam2_generate_mask(\n",
    "    \"./img/test.png\",\n",
    "    model_cfg=model_cfg_0,\n",
    "    checkpoint=sam2_checkpoint,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "points = np.load(\"points.npy\")             # (H, W, 3)，如果你有点云\n",
    "\n",
    "# 3. 配置\n",
    "config = {\n",
    "    'device': 'cuda',\n",
    "    'bounds_min': [-1, -1, -1],\n",
    "    'bounds_max': [1, 1, 1],\n",
    "    'min_dist_bt_keypoints': 0.05,\n",
    "    'seed': 42,\n",
    "    'max_mask_ratio': 0.5,\n",
    "    'num_candidates_per_mask': 5,\n",
    "}\n",
    "candidate_keypoints, projected = get_keypoints(rgb, points, masks, dinov2, config)\n",
    "\n",
    "print(candidate_keypoints.shape)  # (N, 3)\n",
    "cv2.imwrite(\"projected.png\", projected[:, :, ::-1])  # 保存可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28425a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae29340",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_keypoints, projected = get_keypoints(rgb, points, masks, dinov2, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4edc64",
   "metadata": {},
   "source": [
    "print(candidate_keypoints.shape)  # (N, 3)\n",
    "cv2.imwrite(\"projected.png\", projected[:, :, ::-1])  # 保存可视化结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
