{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd87a9db",
   "metadata": {},
   "source": [
    "RGB-D传感器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8089873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from torch.nn.functional import interpolate\n",
    "from kmeans_pytorch import kmeans\n",
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "def filter_points_by_bounds(points, bounds_min, bounds_max, strict=True):\n",
    "    \"\"\"\n",
    "    Filter points by taking only points within workspace bounds.\n",
    "    \"\"\"\n",
    "    assert points.shape[1] == 3, \"points must be (N, 3)\"\n",
    "    bounds_min = bounds_min.copy()\n",
    "    bounds_max = bounds_max.copy()\n",
    "    if not strict:\n",
    "        bounds_min[:2] = bounds_min[:2] - 0.1 * (bounds_max[:2] - bounds_min[:2])\n",
    "        bounds_max[:2] = bounds_max[:2] + 0.1 * (bounds_max[:2] - bounds_min[:2])\n",
    "        bounds_min[2] = bounds_min[2] - 0.1 * (bounds_max[2] - bounds_min[2])\n",
    "    within_bounds_mask = (\n",
    "        (points[:, 0] >= bounds_min[0])\n",
    "        & (points[:, 0] <= bounds_max[0])\n",
    "        & (points[:, 1] >= bounds_min[1])\n",
    "        & (points[:, 1] <= bounds_max[1])\n",
    "        & (points[:, 2] >= bounds_min[2])\n",
    "        & (points[:, 2] <= bounds_max[2])\n",
    "    )\n",
    "    return within_bounds_mask\n",
    "\n",
    "class KeypointProposer:\n",
    "    \"\"\"关键点提议器类，用于从RGB图像和掩码中提取关键点\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"初始化关键点提议器\n",
    "\n",
    "        Args:\n",
    "            config: 配置字典，包含设备、边界、距离等参数\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device(self.config['device'])  # 设置计算设备\n",
    "        # 加载预训练的DINOv2模型\n",
    "        self.dinov3 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').eval().to(self.device)\n",
    "        # 工作空间边界\n",
    "        self.bounds_min = np.array(self.config['bounds_min'])\n",
    "        self.bounds_max = np.array(self.config['bounds_max'])\n",
    "        # MeanShift聚类器，用于合并相近的关键点\n",
    "        self.mean_shift = MeanShift(bandwidth=self.config['min_dist_bt_keypoints'], bin_seeding=True, n_jobs=32)\n",
    "        self.patch_size = 14  # DINOv2的补丁大小\n",
    "        # 设置随机种子以确保结果可重现\n",
    "        np.random.seed(self.config['seed'])\n",
    "        torch.manual_seed(self.config['seed'])\n",
    "        torch.cuda.manual_seed(self.config['seed'])\n",
    "\n",
    "    def get_keypoints(self, rgb, points, masks):\n",
    "        \"\"\"从RGB图像、点云和掩码中提取关键点\n",
    "\n",
    "        Args:\n",
    "            rgb: RGB图像 [H, W, 3]\n",
    "            points: 3D点云 [H, W, 3]\n",
    "            masks: 分割掩码 [H, W]\n",
    "\n",
    "        Returns:\n",
    "            candidate_keypoints: 候选关键点的3D坐标\n",
    "            projected: 在图像上标注关键点的可视化结果\n",
    "        \"\"\"\n",
    "        # 预处理：调整图像尺寸，转换掩码格式\n",
    "        transformed_rgb, rgb, points, masks, shape_info = self._preprocess(rgb, points, masks)\n",
    "\n",
    "        # 使用DINOv2提取特征\n",
    "        features_flat = self._get_features(transformed_rgb, shape_info)\n",
    "\n",
    "        # 对每个掩码区域进行特征聚类，获取关键点候选\n",
    "        candidate_keypoints, candidate_pixels, candidate_rigid_group_ids = self._cluster_features(points, features_flat, masks)\n",
    "\n",
    "        # 过滤掉工作空间外的关键点\n",
    "        within_space = filter_points_by_bounds(candidate_keypoints, self.bounds_min, self.bounds_max, strict=True)\n",
    "        candidate_keypoints = candidate_keypoints[within_space]\n",
    "        candidate_pixels = candidate_pixels[within_space]\n",
    "        candidate_rigid_group_ids = candidate_rigid_group_ids[within_space]\n",
    "\n",
    "        # 在笛卡尔空间中合并相近的点\n",
    "        merged_indices = self._merge_clusters(candidate_keypoints)\n",
    "        candidate_keypoints = candidate_keypoints[merged_indices]\n",
    "        candidate_pixels = candidate_pixels[merged_indices]\n",
    "        candidate_rigid_group_ids = candidate_rigid_group_ids[merged_indices]\n",
    "\n",
    "        # 按位置对候选点进行排序\n",
    "        sort_idx = np.lexsort((candidate_pixels[:, 0], candidate_pixels[:, 1]))\n",
    "        candidate_keypoints = candidate_keypoints[sort_idx]\n",
    "        candidate_pixels = candidate_pixels[sort_idx]\n",
    "        candidate_rigid_group_ids = candidate_rigid_group_ids[sort_idx]\n",
    "\n",
    "        # 将关键点投影到图像空间进行可视化\n",
    "        projected = self._project_keypoints_to_img(rgb, candidate_pixels, candidate_rigid_group_ids, masks, features_flat)\n",
    "\n",
    "        return candidate_keypoints, projected\n",
    "\n",
    "    def _preprocess(self, rgb, points, masks):\n",
    "        \"\"\"预处理输入数据\n",
    "\n",
    "        Args:\n",
    "            rgb: 原始RGB图像\n",
    "            points: 原始点云\n",
    "            masks: 原始掩码\n",
    "\n",
    "        Returns:\n",
    "            transformed_rgb: 调整尺寸后的RGB图像\n",
    "            rgb: 原始RGB图像\n",
    "            points: 原始点云\n",
    "            masks: 转换为二值掩码列表\n",
    "            shape_info: 形状信息字典\n",
    "        \"\"\"\n",
    "        # 将掩码转换为二值掩码列表\n",
    "        masks = [masks == uid for uid in np.unique(masks)]\n",
    "\n",
    "        # 确保输入形状与DINOv2兼容（必须是patch_size的倍数）\n",
    "        H, W, _ = rgb.shape\n",
    "        patch_h = int(H // self.patch_size)  # 垂直方向的补丁数量\n",
    "        patch_w = int(W // self.patch_size)  # 水平方向的补丁数量\n",
    "        new_H = patch_h * self.patch_size    # 调整后的高度\n",
    "        new_W = patch_w * self.patch_size    # 调整后的宽度\n",
    "\n",
    "        # 调整图像尺寸并归一化到[0,1]\n",
    "        transformed_rgb = cv2.resize(rgb, (new_W, new_H))\n",
    "        transformed_rgb = transformed_rgb.astype(np.float32) / 255.0  # float32 [H, W, 3]\n",
    "\n",
    "        # 保存形状信息\n",
    "        shape_info = {\n",
    "            'img_h': H,        # 原始图像高度\n",
    "            'img_w': W,        # 原始图像宽度\n",
    "            'patch_h': patch_h, # 补丁网格高度\n",
    "            'patch_w': patch_w, # 补丁网格宽度\n",
    "        }\n",
    "\n",
    "        return transformed_rgb, rgb, points, masks, shape_info\n",
    "\n",
    "    def _project_keypoints_to_img(self, rgb, candidate_pixels, candidate_rigid_group_ids, masks, features_flat):\n",
    "        \"\"\"将关键点投影到图像上进行可视化\n",
    "\n",
    "        Args:\n",
    "            rgb: 原始RGB图像\n",
    "            candidate_pixels: 候选关键点的像素坐标\n",
    "            candidate_rigid_group_ids: 候选关键点的刚体组ID\n",
    "            masks: 掩码列表\n",
    "            features_flat: 展平的特征\n",
    "\n",
    "        Returns:\n",
    "            projected: 标注了关键点的图像\n",
    "        \"\"\"\n",
    "        projected = rgb.copy()\n",
    "\n",
    "        # 在图像上叠加关键点标注\n",
    "        for keypoint_count, pixel in enumerate(candidate_pixels):\n",
    "            displayed_text = f\"{keypoint_count}\"  # 显示的文本\n",
    "            text_length = len(displayed_text)\n",
    "\n",
    "            # 绘制文本背景框\n",
    "            box_width = 30 + 10 * (text_length - 1)\n",
    "            box_height = 30\n",
    "            # 白色填充矩形\n",
    "            cv2.rectangle(projected,\n",
    "                         (pixel[1] - box_width // 2, pixel[0] - box_height // 2),\n",
    "                         (pixel[1] + box_width // 2, pixel[0] + box_height // 2),\n",
    "                        (255, 255, 255), -1)\n",
    "            # 黑色边框\n",
    "            cv2.rectangle(projected,\n",
    "                         (pixel[1] - box_width // 2, pixel[0] - box_height // 2),\n",
    "                         (pixel[1] + box_width // 2, pixel[0] + box_height // 2),\n",
    "                        (0, 0, 0), 2)\n",
    "\n",
    "            # 绘制关键点编号文本\n",
    "            org = (pixel[1] - 7 * (text_length), pixel[0] + 7)\n",
    "            color = (255, 0, 0)  # 红色文本\n",
    "            cv2.putText(projected, str(keypoint_count), org, cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            keypoint_count += 1\n",
    "\n",
    "        return projected\n",
    "\n",
    "    @torch.inference_mode()  # 禁用梯度计算以节省内存\n",
    "    @torch.amp.autocast('cuda')  # 使用混合精度加速\n",
    "    def _get_features(self, transformed_rgb, shape_info):\n",
    "        \"\"\"使用DINOv2提取图像特征\n",
    "        Args:\n",
    "            transformed_rgb: 预处理后的RGB图像\n",
    "            shape_info: 形状信息字典\n",
    "\n",
    "        Returns:\n",
    "            features_flat: 展平的特征向量 [H*W, feature_dim]\n",
    "        \"\"\"\n",
    "        img_h = shape_info['img_h']\n",
    "        img_w = shape_info['img_w']\n",
    "        patch_h = shape_info['patch_h']\n",
    "        patch_w = shape_info['patch_w']\n",
    "\n",
    "        # 将图像转换为张量格式\n",
    "        img_tensors = torch.from_numpy(transformed_rgb).permute(2, 0, 1).unsqueeze(0).to(self.device)  # [1, 3, H, W]\n",
    "        assert img_tensors.shape[1] == 3, \"unexpected image shape\"\n",
    "\n",
    "        # 使用DINOv2提取特征\n",
    "        features_dict = self.dinov3.forward_features(img_tensors)\n",
    "        raw_feature_grid = features_dict['x_norm_patchtokens']  # [1, patch_h*patch_w, feature_dim]\n",
    "        raw_feature_grid = raw_feature_grid.reshape(1, patch_h, patch_w, -1)  # [1, patch_h, patch_w, feature_dim]\n",
    "\n",
    "        # 使用双线性插值将特征上采样到原始图像尺寸\n",
    "        interpolated_feature_grid = interpolate(\n",
    "            raw_feature_grid.permute(0, 3, 1, 2),  # [1, feature_dim, patch_h, patch_w]\n",
    "            size=(img_h, img_w),\n",
    "            mode='bilinear'\n",
    "        ).permute(0, 2, 3, 1).squeeze(0)  # [H, W, feature_dim]\n",
    "\n",
    "        # 展平特征以便后续处理\n",
    "        features_flat = interpolated_feature_grid.reshape(-1, interpolated_feature_grid.shape[-1])  # [H*W, feature_dim]\n",
    "\n",
    "        return features_flat\n",
    "\n",
    "    def _cluster_features(self, points, features_flat, masks):\n",
    "        \"\"\"对每个掩码区域的特征进行聚类以获取关键点候选\n",
    "\n",
    "        Args:\n",
    "            points: 3D点云\n",
    "            features_flat: 展平的特征\n",
    "            masks: 二值掩码列表\n",
    "\n",
    "        Returns:\n",
    "            candidate_keypoints: 候选关键点的3D坐标\n",
    "            candidate_pixels: 候选关键点的像素坐标\n",
    "            candidate_rigid_group_ids: 候选关键点的刚体组ID\n",
    "        \"\"\"\n",
    "        candidate_keypoints = []\n",
    "        candidate_pixels = []\n",
    "        candidate_rigid_group_ids = []\n",
    "\n",
    "        for rigid_group_id, binary_mask in enumerate(masks):\n",
    "            # 忽略过大的掩码区域\n",
    "            if np.mean(binary_mask) > self.config['max_mask_ratio']:\n",
    "                continue\n",
    "\n",
    "            # 只考虑前景特征\n",
    "            obj_features_flat = features_flat[binary_mask.reshape(-1)]\n",
    "            feature_pixels = np.argwhere(binary_mask)  # 获取掩码内的像素坐标\n",
    "            feature_points = points[binary_mask]       # 获取掩码内的3D点\n",
    "\n",
    "            # 使用PCA降维以减少对噪声和纹理的敏感性\n",
    "            obj_features_flat = obj_features_flat.double()\n",
    "            (u, s, v) = torch.pca_lowrank(obj_features_flat, center=False)\n",
    "            features_pca = torch.mm(obj_features_flat, v[:, :3])  # 保留前3个主成分\n",
    "\n",
    "            # 将PCA特征归一化到[0,1]\n",
    "            features_pca = (features_pca - features_pca.min(0)[0]) / (features_pca.max(0)[0] - features_pca.min(0)[0])\n",
    "            X = features_pca\n",
    "\n",
    "            # 将3D坐标作为额外维度添加到特征中\n",
    "            feature_points_torch = torch.tensor(feature_points, dtype=features_pca.dtype, device=features_pca.device)\n",
    "            feature_points_torch = (feature_points_torch - feature_points_torch.min(0)[0]) / (feature_points_torch.max(0)[0] - feature_points_torch.min(0)[0])\n",
    "            X = torch.cat([X, feature_points_torch], dim=-1)\n",
    "\n",
    "            # 使用K-means聚类获取有意义的区域\n",
    "            cluster_ids_x, cluster_centers = kmeans(\n",
    "                X=X,\n",
    "                num_clusters=self.config['num_candidates_per_mask'],\n",
    "                distance='euclidean',\n",
    "                device=self.device,\n",
    "            )\n",
    "            cluster_centers = cluster_centers.to(self.device)\n",
    "\n",
    "            # 对每个聚类中心，找到最接近的实际点作为关键点候选\n",
    "            for cluster_id in range(self.config['num_candidates_per_mask']):\n",
    "                cluster_center = cluster_centers[cluster_id][:3]  # 只使用PCA特征部分\n",
    "                member_idx = cluster_ids_x == cluster_id\n",
    "                member_points = feature_points[member_idx]\n",
    "                member_pixels = feature_pixels[member_idx]\n",
    "                member_features = features_pca[member_idx]\n",
    "\n",
    "                # 找到距离聚类中心最近的点\n",
    "                dist = torch.norm(member_features - cluster_center, dim=-1)\n",
    "                closest_idx = torch.argmin(dist)\n",
    "\n",
    "                # 添加到候选列表\n",
    "                candidate_keypoints.append(member_points[closest_idx])\n",
    "                candidate_pixels.append(member_pixels[closest_idx])\n",
    "                candidate_rigid_group_ids.append(rigid_group_id)\n",
    "\n",
    "        # 转换为numpy数组\n",
    "        candidate_keypoints = np.array(candidate_keypoints)\n",
    "        candidate_pixels = np.array(candidate_pixels)\n",
    "        candidate_rigid_group_ids = np.array(candidate_rigid_group_ids)\n",
    "\n",
    "        return candidate_keypoints, candidate_pixels, candidate_rigid_group_ids\n",
    "\n",
    "    def _merge_clusters(self, candidate_keypoints):\n",
    "        \"\"\"使用MeanShift合并相近的关键点候选\n",
    "        Args:\n",
    "            candidate_keypoints: 候选关键点的3D坐标\n",
    "        Returns:\n",
    "            merged_indices: 合并后保留的关键点索引\n",
    "        \"\"\"\n",
    "        # 使用MeanShift聚类合并相近的点\n",
    "        self.mean_shift.fit(candidate_keypoints)\n",
    "        cluster_centers = self.mean_shift.cluster_centers_\n",
    "        # 对每个聚类中心，找到最接近的原始候选点\n",
    "        merged_indices = []\n",
    "        for center in cluster_centers:\n",
    "            dist = np.linalg.norm(candidate_keypoints - center, axis=-1)\n",
    "            merged_indices.append(np.argmin(dist))\n",
    "        return merged_indices\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
